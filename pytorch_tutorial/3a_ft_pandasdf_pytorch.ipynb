{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch with a Pandas DataFrame input (tabulated iris data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A Dataloader is a Pytorch class that allows for easy training and inference, therefore whenever a Pandas dataframe is used as input, it must converted to a Dataloader object ie. a class that includes an __init__, __len__, and __getitem__ function. Since the __getitem__ only returns the index of the row as a Pandas class, it must be converted to a torch.tensor(). This can be done either in the class itself or when creating the object (see below).\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "class PandasPytorchDataLoader(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        return self.data.iloc[idx]\n",
    "'''\n",
    "\n",
    "then feed your scaled features and label encoded classes to TensorDataset\n",
    "\n",
    "model = IrisClassifier(in_features=train_X.shape[1], out_features=64)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from torch.nn import Linear, Embedding, CrossEntropyLoss\n",
    "from torch.nn.functional import cross_entropy\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(99)\n",
    "df = sns.load_dataset('iris')\n",
    "df.head()\n",
    "# type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset\n",
    "df = df.sample(frac=1, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine unique labels\n",
    "species_class_labels = {'virginica': 2, 'versicolor': 1, 'setosa': 0}\n",
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(df.iloc[:,:-1])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode the species category\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df.iloc[:,-1])\n",
    "labels.shape\n",
    "labels\n",
    "type(features), features.dtype, features.shape, type(labels), labels.dtype, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 60-20-20 split between training, cross validation, and testin\n",
    "df_size = len(df)\n",
    "training_size = int(df_size * .8)\n",
    "testing_size = int(df_size - training_size)\n",
    "training_size, testing_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing arrays\n",
    "train_X, train_y = features[:training_size+1], labels[:training_size+1]\n",
    "test_X, test_y = features[training_size+1:], labels[training_size+1:]\n",
    "\n",
    "train_test_data = [train_X, train_y, test_X, test_y]\n",
    "\n",
    "for d in train_test_data:\n",
    "    print(type(d), d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to tensors\n",
    "\n",
    "train_X_tensor = torch.tensor(train_X, dtype=torch.float32)\n",
    "train_y_tensor = torch.tensor(train_y, dtype=torch.int64)\n",
    "\n",
    "test_X_tensor = torch.tensor(test_X, dtype=torch.float32)\n",
    "test_y_tensor = torch.tensor(test_y, dtype=torch.int64)\n",
    "test_y_tensor.shape, type(test_y_tensor), test_y_tensor.dtype, len(test_y_tensor), test_X_tensor.shape, type(test_X_tensor), test_X_tensor.dtype, len(test_X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pytorch Model\n",
    "\n",
    "class IrisClassifier(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        super().__init__()\n",
    "        # self.embedding_layer = Embedding(num_embeddings, embedding_dim)\n",
    "        self.linear_layer_1 = Linear(in_features=in_features, out_features=out_features)\n",
    "        self.linear_layer_2 = Linear(in_features=out_features, out_features=3)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = self.linear_layer_1(features)\n",
    "        y = self.linear_layer_2(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate model\n",
    "model = IrisClassifier(in_features=train_X.shape[1], out_features=64)\n",
    "model\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish loss, optimizer, epochs, and batch_size\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# loss_2 = cross_entropy(input=, target=, )\n",
    "loss_cel = CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize the data loader class for both BATCH training \n",
    "\n",
    "\n",
    "# ??? and testing tensors to ensure the data complies with Pytorch\n",
    "train_dataset = TensorDataset(train_X_tensor, train_y_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# tester_dataloader = DataLoader((test_X_tensor, test_y_tensor), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_features, labels_features in train_dataloader:\n",
    "\n",
    "        # resets the gradients of all the parameters to zero so no mini-batch gradients will after the next traiing step on a new set of batch data\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        # outputs\n",
    "        logits = model(batch_features)\n",
    "\n",
    "        # loss = cross_entropy(logits[0], target=labels_features[0])\n",
    "        loss = loss_cel(logits[0], target=labels_features[0])\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}, Running Loss: {running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model \n",
    "\n",
    "with torch.no_grad():\n",
    "    test_logits = model(test_X_tensor)\n",
    "\n",
    "    _, predicted = torch.max(test_logits, 1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=test_y_tensor.numpy(), y_pred=predicted)\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model \n",
    "\n",
    "torch.save(model.state_dict(), 'iris_pytorch_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a locally saved model\n",
    "\n",
    "loaded_model = torch.load('iris_pytorch_classifier.pth')\n",
    "loaded_model\n",
    "type(loaded_model), len(loaded_model)\n",
    "predicted\n",
    "test_y_tensor\n",
    "accuracy_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for y_pred,  y_test in zip(pred_y, test_y_tensor):\n",
    "for y_pred,  y_test in zip(predicted, test_y_tensor):\n",
    "    print(f\"Predicted Label: {y_pred},    True Label: {y_test}\")\n",
    "    if y_pred == y_test:\n",
    "        accuracy_count += 1\n",
    "print(accuracy_count/len(predicted))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
